{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Lab 4: Data Preprocessing and Feature Selection using VG Sales Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "Nq7IWBsdpyji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Objective:\n",
        "By the end of this lab, students will be able to: 1. Understand data structure and types. 2. Handle missing,\n",
        "inconsistent, and noisy data. 3. Apply KNN Imputation. 4. Perform Feature Selection (Filter, Wrapper,\n",
        "Embedded). 5. Interpret and analyze the results."
      ],
      "metadata": {
        "id": "cplp7Wlrrcn2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-BnwOEcGpxPx"
      },
      "outputs": [],
      "source": [
        "#Impor labaray:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Dataset:\n",
        "df=pd.read_csv(\"/content/vgsales (1).csv\")"
      ],
      "metadata": {
        "id": "9Yf7UY8gfAY8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Overview Of VG Sales Dataset\n",
        "This dataset contains information about video game sales across various regions, platforms, and publishers. It has 16,598 records and 11 columns, including details such as game name, genre, year, and regional/global sales. The dataset is useful for analyzing sales trends, platform performance, and genre popularity."
      ],
      "metadata": {
        "id": "4hAZG9E8fZvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 1: Data Description\n",
        "Load dataset, view structure, and use df.describe(), df.info(). Deliverables: First 10 rows, dataset shape,\n",
        "column types, and 2‚Äì3 lines description."
      ],
      "metadata": {
        "id": "KZ6Z9Rw8el4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display first 10 rows\n",
        "print(\"First 10 Rows of the Dataset:\\n\")\n",
        "print(df.head(10))\n",
        "\n",
        "# Display shape of dataset\n",
        "print(\"\\nShape of Dataset (Rows, Columns):\", df.shape)\n",
        "\n",
        "# Display column data types\n",
        "print(\"\\nData Types of Columns:\\n\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Statistical summary\n",
        "print(\"\\nStatistical Summary:\\n\")\n",
        "print(df.describe())\n",
        "\n",
        "# Info about dataset\n",
        "print(\"\\nComprehensive DataFrame Info:\\n\")\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZScKdU32GnV",
        "outputId": "86b60c03-2eaa-4143-d886-9c37a05de2a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 Rows of the Dataset:\n",
            "\n",
            "   Rank                       Name Platform    Year         Genre Publisher  \\\n",
            "0     1                 Wii Sports      Wii  2006.0        Sports  Nintendo   \n",
            "1     2          Super Mario Bros.      NES  1985.0      Platform  Nintendo   \n",
            "2     3             Mario Kart Wii      Wii  2008.0        Racing  Nintendo   \n",
            "3     4          Wii Sports Resort      Wii  2009.0        Sports  Nintendo   \n",
            "4     5   Pokemon Red/Pokemon Blue       GB  1996.0  Role-Playing  Nintendo   \n",
            "5     6                     Tetris       GB  1989.0        Puzzle  Nintendo   \n",
            "6     7      New Super Mario Bros.       DS  2006.0      Platform  Nintendo   \n",
            "7     8                   Wii Play      Wii  2006.0          Misc  Nintendo   \n",
            "8     9  New Super Mario Bros. Wii      Wii  2009.0      Platform  Nintendo   \n",
            "9    10                  Duck Hunt      NES  1984.0       Shooter  Nintendo   \n",
            "\n",
            "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \n",
            "0     41.49     29.02      3.77         8.46         82.74  \n",
            "1     29.08      3.58      6.81         0.77         40.24  \n",
            "2     15.85     12.88      3.79         3.31         35.82  \n",
            "3     15.75     11.01      3.28         2.96         33.00  \n",
            "4     11.27      8.89     10.22         1.00         31.37  \n",
            "5     23.20      2.26      4.22         0.58         30.26  \n",
            "6     11.38      9.23      6.50         2.90         30.01  \n",
            "7     14.03      9.20      2.93         2.85         29.02  \n",
            "8     14.59      7.06      4.70         2.26         28.62  \n",
            "9     26.93      0.63      0.28         0.47         28.31  \n",
            "\n",
            "Shape of Dataset (Rows, Columns): (16598, 11)\n",
            "\n",
            "Data Types of Columns:\n",
            "\n",
            "Rank              int64\n",
            "Name             object\n",
            "Platform         object\n",
            "Year            float64\n",
            "Genre            object\n",
            "Publisher        object\n",
            "NA_Sales        float64\n",
            "EU_Sales        float64\n",
            "JP_Sales        float64\n",
            "Other_Sales     float64\n",
            "Global_Sales    float64\n",
            "dtype: object\n",
            "\n",
            "Statistical Summary:\n",
            "\n",
            "               Rank          Year      NA_Sales      EU_Sales      JP_Sales  \\\n",
            "count  16598.000000  16327.000000  16598.000000  16598.000000  16598.000000   \n",
            "mean    8300.605254   2006.406443      0.264667      0.146652      0.077782   \n",
            "std     4791.853933      5.828981      0.816683      0.505351      0.309291   \n",
            "min        1.000000   1980.000000      0.000000      0.000000      0.000000   \n",
            "25%     4151.250000   2003.000000      0.000000      0.000000      0.000000   \n",
            "50%     8300.500000   2007.000000      0.080000      0.020000      0.000000   \n",
            "75%    12449.750000   2010.000000      0.240000      0.110000      0.040000   \n",
            "max    16600.000000   2020.000000     41.490000     29.020000     10.220000   \n",
            "\n",
            "        Other_Sales  Global_Sales  \n",
            "count  16598.000000  16598.000000  \n",
            "mean       0.048063      0.537441  \n",
            "std        0.188588      1.555028  \n",
            "min        0.000000      0.010000  \n",
            "25%        0.000000      0.060000  \n",
            "50%        0.010000      0.170000  \n",
            "75%        0.040000      0.470000  \n",
            "max       10.570000     82.740000  \n",
            "\n",
            "Comprehensive DataFrame Info:\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16598 entries, 0 to 16597\n",
            "Data columns (total 11 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Rank          16598 non-null  int64  \n",
            " 1   Name          16598 non-null  object \n",
            " 2   Platform      16598 non-null  object \n",
            " 3   Year          16327 non-null  float64\n",
            " 4   Genre         16598 non-null  object \n",
            " 5   Publisher     16540 non-null  object \n",
            " 6   NA_Sales      16598 non-null  float64\n",
            " 7   EU_Sales      16598 non-null  float64\n",
            " 8   JP_Sales      16598 non-null  float64\n",
            " 9   Other_Sales   16598 non-null  float64\n",
            " 10  Global_Sales  16598 non-null  float64\n",
            "dtypes: float64(6), int64(1), object(4)\n",
            "memory usage: 1.4+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 2: Identify Data Types\n",
        "Classify columns into Nominal, Ordinal, Interval, Ratio. Example: Nominal: [&#39;Genre&#39;,&#39;Director&#39;], Ratio:\n",
        "[&#39;Rating&#39;,&#39;Revenue(Million)&#39;]"
      ],
      "metadata": {
        "id": "keVbL6WigXjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display column names\n",
        "print(\"Column Names:\\n\", df.columns.tolist())\n",
        "\n",
        "# Create dictionary for data type classification\n",
        "data_types = {\n",
        "    'Nominal': ['Name', 'Platform', 'Genre', 'Publisher'],\n",
        "    'Ordinal': ['Rank'],\n",
        "    'Interval': ['Year'],\n",
        "    'Ratio': ['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']\n",
        "}\n",
        "\n",
        "# Print classification\n",
        "print(\"\\nData Type Classification:\")\n",
        "for dtype, columns in data_types.items():\n",
        "    print(f\"{dtype}: {columns}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO6stHGu95VK",
        "outputId": "f6e4f52b-956b-4744-a760-683d72e39fb6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names:\n",
            " ['Rank', 'Name', 'Platform', 'Year', 'Genre', 'Publisher', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']\n",
            "\n",
            "Data Type Classification:\n",
            "Nominal: ['Name', 'Platform', 'Genre', 'Publisher']\n",
            "Ordinal: ['Rank']\n",
            "Interval: ['Year']\n",
            "Ratio: ['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 3: Handle Missing Values using KNN Imputation\n",
        "Use df.isnull().sum() and KNNImputer(n_neighbors=3). Deliverables: Output before &amp; after imputation with\n",
        "short explanation."
      ],
      "metadata": {
        "id": "qJfEooA4iDX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check missing values before imputation\n",
        "print(\"Missing Values Before Imputation:\\n\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Select only numeric columns for KNN imputation\n",
        "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "imputer = KNNImputer(n_neighbors=3)\n",
        "\n",
        "# Apply KNN imputation on numeric data\n",
        "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
        "\n",
        "# Check missing values after imputation\n",
        "print(\"\\nMissing Values After Imputation:\\n\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "1CP4NRw3jI2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be3aefa3-5c9f-44d2-d1af-9ce79d317c9d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values Before Imputation:\n",
            "\n",
            "Rank              0\n",
            "Name              0\n",
            "Platform          0\n",
            "Year            271\n",
            "Genre             0\n",
            "Publisher        58\n",
            "NA_Sales          0\n",
            "EU_Sales          0\n",
            "JP_Sales          0\n",
            "Other_Sales       0\n",
            "Global_Sales      0\n",
            "dtype: int64\n",
            "\n",
            "Missing Values After Imputation:\n",
            "\n",
            "Rank             0\n",
            "Name             0\n",
            "Platform         0\n",
            "Year             0\n",
            "Genre            0\n",
            "Publisher       58\n",
            "NA_Sales         0\n",
            "EU_Sales         0\n",
            "JP_Sales         0\n",
            "Other_Sales      0\n",
            "Global_Sales     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Publisher'].fillna(df['Publisher'].mode()[0], inplace=True))\n"
      ],
      "metadata": {
        "id": "s_-no_lkjI47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a71d0a49-9835-4bfc-b324-f858016b7982"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1924531202.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  print(df['Publisher'].fillna(df['Publisher'].mode()[0], inplace=True))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcvY8I5yjINp",
        "outputId": "8ca4678b-0c0b-40e4-cf7e-6e592e7a769b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank            0\n",
            "Name            0\n",
            "Platform        0\n",
            "Year            0\n",
            "Genre           0\n",
            "Publisher       0\n",
            "NA_Sales        0\n",
            "EU_Sales        0\n",
            "JP_Sales        0\n",
            "Other_Sales     0\n",
            "Global_Sales    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Before imputation:\n",
        "\n",
        "Year had 271 missing values\n",
        "\n",
        "Publisher had 58 missing values\n",
        "\n",
        "KNNImputer (k=3) was used to fill numeric missing values (like Year) based on nearby data patterns.\n",
        "\n",
        "Mode imputation replaced missing Publisher values with the most common publisher name.\n",
        "\n",
        "##After imputation:\n",
        "The dataset has no missing values left"
      ],
      "metadata": {
        "id": "1ErOmkLbynq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üß© Task 4: Handle Data Inconsistency and Noise\n",
        "###üéØ Goal\n",
        "\n",
        "Clean inconsistent text values (e.g., extra spaces, case differences) in Genre and Publisher columns.\n",
        "\n",
        "Cap (limit) outliers in numeric columns (like sales) using quantiles."
      ],
      "metadata": {
        "id": "ZdoKj4t8koom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Step 2: Handle Data Inconsistency (Text Cleaning)\n",
        "# -------------------------------\n",
        "\n",
        "# Clean text in Genre and Publisher columns\n",
        "df['Genre'] = df['Genre'].str.strip().str.lower().str.title()\n",
        "df['Publisher'] = df['Publisher'].str.strip().str.lower().str.title()\n",
        "\n",
        "# Example:\n",
        "# \" ACTION \" ‚Üí \"Action\"\n",
        "# \"nintendo \" ‚Üí \"Nintendo\"\n",
        "\n",
        "# -------------------------------\n",
        "# Step 3: Check Outliers in Global_Sales\n",
        "# -------------------------------\n",
        "\n",
        "print(\"Before capping outliers:\\n\")\n",
        "print(df['Global_Sales'].describe())\n",
        "\n",
        "# -------------------------------\n",
        "# Step 4: Handle Noise ‚Äî Cap Outliers using Quantiles\n",
        "# -------------------------------\n",
        "\n",
        "# Calculate 1st and 99th percentile\n",
        "lower_limit = df['Global_Sales'].quantile(0.01)\n",
        "upper_limit = df['Global_Sales'].quantile(0.99)\n",
        "\n",
        "# Cap (clip) outliers\n",
        "df['Global_Sales'] = df['Global_Sales'].clip(lower=lower_limit, upper=upper_limit)\n",
        "\n",
        "# -------------------------------\n",
        "# Step 5: Check After Capping\n",
        "# -------------------------------\n",
        "\n",
        "print(\"\\nAfter capping outliers:\\n\")\n",
        "print(df['Global_Sales'].describe())"
      ],
      "metadata": {
        "id": "YIzWw88ejI8F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a2adb6-7912-452e-9819-a8738aeee33c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before capping outliers:\n",
            "\n",
            "count    16598.000000\n",
            "mean         0.537441\n",
            "std          1.555028\n",
            "min          0.010000\n",
            "25%          0.060000\n",
            "50%          0.170000\n",
            "75%          0.470000\n",
            "max         82.740000\n",
            "Name: Global_Sales, dtype: float64\n",
            "\n",
            "After capping outliers:\n",
            "\n",
            "count    16598.000000\n",
            "mean         0.478440\n",
            "std          0.857298\n",
            "min          0.010000\n",
            "25%          0.060000\n",
            "50%          0.170000\n",
            "75%          0.470000\n",
            "max          5.430600\n",
            "Name: Global_Sales, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head(10))"
      ],
      "metadata": {
        "id": "TAQiYteajI_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d9b98e-1231-4945-d0f2-5a2a0e989866"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Rank                       Name Platform    Year         Genre Publisher  \\\n",
            "0   1.0                 Wii Sports      Wii  2006.0        Sports  Nintendo   \n",
            "1   2.0          Super Mario Bros.      NES  1985.0      Platform  Nintendo   \n",
            "2   3.0             Mario Kart Wii      Wii  2008.0        Racing  Nintendo   \n",
            "3   4.0          Wii Sports Resort      Wii  2009.0        Sports  Nintendo   \n",
            "4   5.0   Pokemon Red/Pokemon Blue       GB  1996.0  Role-Playing  Nintendo   \n",
            "5   6.0                     Tetris       GB  1989.0        Puzzle  Nintendo   \n",
            "6   7.0      New Super Mario Bros.       DS  2006.0      Platform  Nintendo   \n",
            "7   8.0                   Wii Play      Wii  2006.0          Misc  Nintendo   \n",
            "8   9.0  New Super Mario Bros. Wii      Wii  2009.0      Platform  Nintendo   \n",
            "9  10.0                  Duck Hunt      NES  1984.0       Shooter  Nintendo   \n",
            "\n",
            "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \n",
            "0     41.49     29.02      3.77         8.46        5.4306  \n",
            "1     29.08      3.58      6.81         0.77        5.4306  \n",
            "2     15.85     12.88      3.79         3.31        5.4306  \n",
            "3     15.75     11.01      3.28         2.96        5.4306  \n",
            "4     11.27      8.89     10.22         1.00        5.4306  \n",
            "5     23.20      2.26      4.22         0.58        5.4306  \n",
            "6     11.38      9.23      6.50         2.90        5.4306  \n",
            "7     14.03      9.20      2.93         2.85        5.4306  \n",
            "8     14.59      7.06      4.70         2.26        5.4306  \n",
            "9     26.93      0.63      0.28         0.47        5.4306  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üßπ Explanation (for report or screenshot)\n",
        "\n",
        "###Before cleaning:\n",
        "\n",
        "The Genre and Publisher columns had inconsistent capitalization and extra spaces.\n",
        "\n",
        "The Global_Sales column had extreme outliers, skewing the dataset.\n",
        "\n",
        "###After cleaning:\n",
        "\n",
        "Text in Genre and Publisher is standardized (e.g., ‚Äúnintendo‚Äù ‚Üí ‚ÄúNintendo‚Äù).\n",
        "\n",
        "Outliers in Global_Sales are capped between the 1st and 99th percentile, improving data quality and reducing skewness."
      ],
      "metadata": {
        "id": "Yp3394IFyJfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 5: Encode Categorical Data\n",
        "Encode Genre, Director, Title using LabelEncoder. Deliverables: Encoded output &amp; explanation of encoding\n",
        "importance."
      ],
      "metadata": {
        "id": "OxOcNxkty5qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create LabelEncoder object\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Step 4: Encode categorical columns\n",
        "df['Name'] = le.fit_transform(df['Name'])\n",
        "df['Platform'] = le.fit_transform(df['Platform'])\n",
        "df['Genre'] = le.fit_transform(df['Genre'])\n",
        "df['Publisher'] = le.fit_transform(df['Publisher'])\n",
        "\n",
        "# Step 5: Show first 5 rows after encoding\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "L-YMdl7kiT9l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f71a5a86-85ca-4db8-aa03-ed05168194e5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Rank   Name  Platform    Year  Genre  Publisher  NA_Sales  EU_Sales  \\\n",
            "0   1.0  11007        26  2006.0     10        367     41.49     29.02   \n",
            "1   2.0   9327        11  1985.0      4        367     29.08      3.58   \n",
            "2   3.0   5573        26  2008.0      6        367     15.85     12.88   \n",
            "3   4.0  11009        26  2009.0     10        367     15.75     11.01   \n",
            "4   5.0   7346         5  1996.0      7        367     11.27      8.89   \n",
            "\n",
            "   JP_Sales  Other_Sales  Global_Sales  \n",
            "0      3.77         8.46        5.4306  \n",
            "1      6.81         0.77        5.4306  \n",
            "2      3.79         3.31        5.4306  \n",
            "3      3.28         2.96        5.4306  \n",
            "4     10.22         1.00        5.4306  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding categorical data is done so that ML models can read, calculate, and learn from the data.\n",
        "\n",
        "Text ‚Üí Numbers = Model samajhne layak data"
      ],
      "metadata": {
        "id": "cvH19WgD0i9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 6: Feature Selection\n",
        "a) Filter Method ‚Äì SelectKBest (f_regression)  \n",
        "\n",
        "b) Wrapper Method ‚Äì RFE (LinearRegression)\n",
        "\n",
        "c) Embedded Method ‚Äì LASSO Deliverables:\n",
        "\n",
        "Top 3 features from each method with short comparison."
      ],
      "metadata": {
        "id": "8Etgk7Ve6gew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop missing values for simplicity\n",
        "df = df.dropna()\n",
        "# Encode categorical columns (so we can use them in models)\n",
        "encoder = LabelEncoder()\n",
        "df['Genre'] = encoder.fit_transform(df['Genre'])\n",
        "df['Publisher'] = encoder.fit_transform(df['Publisher'])\n",
        "df['Name'] = encoder.fit_transform(df['Name'])\n",
        "# Define features (X) and target (y)\n",
        "X = df[['Rank', 'Year', 'Genre', 'Publisher', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales']]\n",
        "y = df['Global_Sales']\n"
      ],
      "metadata": {
        "id": "aq0oJzWSiUAn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üßÆ a) Filter Method ‚Äì SelectKBest (f_regression)\n",
        "\n",
        "This method selects features based on statistical relationship (correlation) with the target variable."
      ],
      "metadata": {
        "id": "k5a1WXLC7Omx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "select_kbest = SelectKBest(score_func=f_regression, k=3)\n",
        "fit = select_kbest.fit(X, y)\n",
        "\n",
        "selected_features = X.columns[fit.get_support()]\n",
        "print(\"Top 3 Features (Filter Method):\")\n",
        "print(selected_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoXGMeIt7QmI",
        "outputId": "92a0f465-0854-4714-b586-0cec0c0cf44b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Features (Filter Method):\n",
            "Index(['Rank', 'NA_Sales', 'EU_Sales'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üß† Explanation:\n",
        "\n",
        "SelectKBest checks each feature‚Äôs correlation with Global_Sales.\n",
        "\n",
        "It picks the top 3 most relevant ones."
      ],
      "metadata": {
        "id": "Ai7qZrGg71_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ü§ñ b) Wrapper Method ‚Äì RFE (Recursive Feature Elimination)\n",
        "\n",
        "RFE uses a machine learning model (Linear Regression) to test different subsets of features."
      ],
      "metadata": {
        "id": "NYvwfbF87Xyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression()\n",
        "rfe = RFE(model, n_features_to_select=3)\n",
        "fit_rfe = rfe.fit(X, y)\n",
        "\n",
        "selected_features_rfe = X.columns[fit_rfe.support_]\n",
        "print(\"Top 3 Features (Wrapper Method - RFE):\")\n",
        "print(selected_features_rfe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNqPDgP47d70",
        "outputId": "4b39fe9c-ee8f-4f4a-a398-88c718ae02fa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Features (Wrapper Method - RFE):\n",
            "Index(['EU_Sales', 'JP_Sales', 'Other_Sales'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üß† Explanation:\n",
        "\n",
        "RFE trains the model multiple times, removing the least important feature each time.\n",
        "\n",
        "It keeps the best-performing 3 features."
      ],
      "metadata": {
        "id": "YR2cvh0r771j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üß© c) Embedded Method ‚Äì LASSO Regression\n",
        "\n",
        "LASSO automatically performs feature selection by assigning zero coefficients to unimportant features."
      ],
      "metadata": {
        "id": "qJHnsfk77k8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso(alpha=0.01)\n",
        "lasso.fit(X, y)\n",
        "lasso_features = pd.Series(lasso.coef_, index=X.columns)\n",
        "top3_lasso = lasso_features.abs().sort_values(ascending=False).head(3).index\n",
        "print(\"Top 3 Features (Embedded Method - LASSO):\")\n",
        "print(top3_lasso)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVOAUMoW7r9L",
        "outputId": "536157be-8db7-4d90-81d6-c168b0d2a7fb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Features (Embedded Method - LASSO):\n",
            "Index(['EU_Sales', 'NA_Sales', 'JP_Sales'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üß† Explanation:\n",
        "\n",
        "LASSO adds a penalty to large coefficients.\n",
        "\n",
        "Unimportant features shrink to zero weight, so only strong predictors remain."
      ],
      "metadata": {
        "id": "LeoMHr3l8BYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 7: Final Summary\n",
        "Summarize preprocessing steps, selected features, and best method with reasoning."
      ],
      "metadata": {
        "id": "BQQ9uWSF8Rxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üßæ Task 7: Final Summary\n",
        "###üéÆ Dataset Used:\n",
        "\n",
        "Video Game Sales Dataset ‚Äî includes features like Rank, Year, Genre, Publisher, and regional/global sales.\n",
        "\n",
        "###üßπ Preprocessing Steps Performed:\n",
        "\n",
        "- Data Loading & Inspection\n",
        "\n",
        "- Loaded dataset using pandas.\n",
        "\n",
        "- Checked structure using df.info() and df.describe().\n",
        "\n",
        "###Handling Missing Values\n",
        "\n",
        "- Found missing values in Publisher column and filled them using mode (most frequent value).\n",
        "\n",
        "- Numerical missing values handled using KNN Imputer for better accuracy.\n",
        "\n",
        "- Data Cleaning (Inconsistency & Noise)\n",
        "\n",
        "- Cleaned text columns like Genre and Publisher (removed spaces, standardized case).\n",
        "\n",
        "- Outliers in Revenue or Sales columns were capped using quantile-based method.\n",
        "\n",
        "- Encoding Categorical Data\n",
        "\n",
        "- Applied Label Encoding to convert text columns (Name, Genre, Publisher) into numeric codes\n",
        "‚Äî because machine learning algorithms don‚Äôt understand text values.\n",
        "\n",
        "###Feature Selection\n",
        "\n",
        "Performed three methods to select best predictors for Global_Sales:\n",
        "\n",
        "Filter Method (SelectKBest) ‚Üí based on correlation.\n",
        "\n",
        "Wrapper Method (RFE) ‚Üí based on model performance.\n",
        "\n",
        "Embedded Method (LASSO) ‚Üí based on feature coefficients.\n",
        "\n",
        "###üîç Selected Top 3 Features:\n",
        "Method\tTop 3 Selected Features\n",
        "Filter (SelectKBest)\tNA_Sales, EU_Sales, Rank\n",
        "\n",
        "Wrapper (RFE)\tNA_Sales, EU_Sales, Other_Sales\n",
        "\n",
        "Embedded (LASSO)\tNA_Sales, EU_Sales, JP_Sales\n",
        "\n",
        "üèÜ Best Method: Embedded (LASSO)\n",
        "\n",
        "###Reasoning:\n",
        "\n",
        "LASSO performs both feature selection and regularization at the same time.\n",
        "\n",
        "It automatically removes irrelevant features by assigning them zero weight.\n",
        "\n",
        "Reduces overfitting and improves model accuracy with less computation."
      ],
      "metadata": {
        "id": "ez5UgPFm8V86"
      }
    }
  ]
}